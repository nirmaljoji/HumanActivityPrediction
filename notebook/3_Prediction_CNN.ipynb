{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMrtK74Vz-C8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import importlib\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tensorflow import keras\n",
        "import torch\n",
        "from tensorflow.keras import layers\n",
        "import keras.backend as K\n",
        "from keras import regularizers\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, Lambda\n",
        "from keras.layers import GRU, Dense, Activation, Dropout, concatenate, Input, BatchNormalization\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import math\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch.nn as nn\n",
        "import time\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, accuracy_score, f1_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "from pathlib import Path\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgimKjyC0nVX"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHME4y05xjwV",
        "outputId": "b38b00d8-264f-44e1-b7e4-a8bf6664e9a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZaqNE7Dzf_m",
        "outputId": "9a160765-fe0a-484a-84f4-2fd0dde07d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial01_x.csv  Trial02_x.csv  Trial03_x.csv  Trial04_x.csv\n",
            "Trial01_y.csv  Trial02_y.csv  Trial03_y.csv  Trial04_y.csv\n"
          ]
        }
      ],
      "source": [
        "!ls drive/MyDrive/GaitData/data/test/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0HJYWZ2HHOi",
        "outputId": "998ca4a1-9d43-45fc-fc81-0a79b59a7c71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37890\n",
            "9473\n",
            "Unique labels: [nan  0.  1.  2.  3.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 6441 occurrences\n",
            "Label 3.0: 1530 occurrences\n",
            "Label 2.0: 788 occurrences\n",
            "Label 1.0: 711 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0   1        0.0  4.435275  8.196063  2.974488  0.014215 -0.039157 -0.016744   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "70172\n",
            "17543\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 12563 occurrences\n",
            "Label 3.0: 2852 occurrences\n",
            "Label 2.0: 1148 occurrences\n",
            "Label 1.0: 977 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0   2        0.0  1.726654  9.619981  1.723327 -0.001997  0.067502  0.126057   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "43146\n",
            "10787\n",
            "Unique labels: [nan  0.  1.  2.  3.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 8292 occurrences\n",
            "Label 2.0: 1106 occurrences\n",
            "Label 3.0: 709 occurrences\n",
            "Label 1.0: 673 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0   3        0.0 -0.800765  9.454945  1.610219  0.013318  0.155152  0.062953   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "54956\n",
            "13739\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 9878 occurrences\n",
            "Label 3.0: 1745 occurrences\n",
            "Label 1.0: 1226 occurrences\n",
            "Label 2.0: 881 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0   4        0.0  1.524319  9.704319  0.185681 -0.006484  0.001111 -0.001111   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "59121\n",
            "14780\n",
            "Unique labels: [nan  0.  1.  2.  3.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 11066 occurrences\n",
            "Label 2.0: 1751 occurrences\n",
            "Label 1.0: 1130 occurrences\n",
            "Label 3.0: 833 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0   5        0.0  1.883375  9.517874  0.350562  0.012344 -0.003333 -0.006996   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "38631\n",
            "9658\n",
            "Unique labels: [nan  0.  2.  1.  3.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 8307 occurrences\n",
            "Label 1.0: 625 occurrences\n",
            "Label 2.0: 572 occurrences\n",
            "Label 3.0: 146 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z  gyro_x    gyro_y    gyro_z  \\\n",
            "0   6        0.0  1.243831  9.170092  3.713738  0.0327 -0.003023 -0.006189   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "31423\n",
            "7856\n",
            "Unique labels: [nan  0.  2.  3.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 6633 occurrences\n",
            "Label 3.0: 770 occurrences\n",
            "Label 2.0: 447 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0   7        0.0  1.120644  9.395322  2.584678  0.002222 -0.009778 -0.007852   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "66762\n",
            "16691\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 8117 occurrences\n",
            "Label 3.0: 7431 occurrences\n",
            "Label 2.0: 637 occurrences\n",
            "Label 1.0: 505 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0   8        0.0  0.122837  9.807163  0.816419 -0.009326 -0.020874 -0.006532   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "55999\n",
            "14000\n",
            "Unique labels: [nan  0.  1.  2.  3.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 11037 occurrences\n",
            "Label 3.0: 1719 occurrences\n",
            "Label 2.0: 727 occurrences\n",
            "Label 1.0: 507 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0   9        0.0  1.570664  9.721734  0.741734  0.001711  0.006369  0.004535   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "55401\n",
            "13850\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 9702 occurrences\n",
            "Label 3.0: 3414 occurrences\n",
            "Label 2.0: 493 occurrences\n",
            "Label 1.0: 241 occurrences\n",
            "   id  timestamp   accel_x  accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  10        0.0  1.003241     9.48  2.355139  0.000242  0.002015  0.000485   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "48797\n",
            "12199\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 9060 occurrences\n",
            "Label 3.0: 2317 occurrences\n",
            "Label 2.0: 501 occurrences\n",
            "Label 1.0: 312 occurrences\n",
            "   id  timestamp   accel_x  accel_y  accel_z    gyro_x    gyro_y   gyro_z  \\\n",
            "0  11        0.0  1.493221  9.50226     1.83 -0.004442 -0.001104 -0.00111   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "51461\n",
            "12865\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 9854 occurrences\n",
            "Label 3.0: 2106 occurrences\n",
            "Label 2.0: 483 occurrences\n",
            "Label 1.0: 417 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z   gyro_x    gyro_y    gyro_z  \\\n",
            "0  12        0.0  1.442759  9.486379  1.706379  0.00111 -0.001152  0.002157   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "42319\n",
            "10580\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 7547 occurrences\n",
            "Label 3.0: 2130 occurrences\n",
            "Label 1.0: 472 occurrences\n",
            "Label 2.0: 421 occurrences\n",
            "   id  timestamp   accel_x  accel_y  accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  13        0.0  0.698097  9.68865  0.84865 -0.001344  0.001767  0.001548   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "36313\n",
            "9078\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 6911 occurrences\n",
            "Label 3.0: 953 occurrences\n",
            "Label 2.0: 678 occurrences\n",
            "Label 1.0: 528 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  14        0.0 -1.173102  9.536898  1.657673 -0.003333  0.032875 -0.023092   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "47210\n",
            "11803\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 10061 occurrences\n",
            "Label 3.0: 1170 occurrences\n",
            "Label 1.0: 463 occurrences\n",
            "Label 2.0: 106 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  15        0.0 -0.452458  9.482034  2.475508  0.000296 -0.032813 -0.044811   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "19533\n",
            "4883\n",
            "Unique labels: [nan  0.  2.  3.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 3562 occurrences\n",
            "Label 3.0: 908 occurrences\n",
            "Label 2.0: 410 occurrences\n",
            "   id  timestamp  accel_x  accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  16        0.0 -1.13518  8.94777  3.385901  0.037634 -0.087972 -0.023108   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "56079\n",
            "14020\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 11656 occurrences\n",
            "Label 3.0: 1364 occurrences\n",
            "Label 2.0: 551 occurrences\n",
            "Label 1.0: 439 occurrences\n",
            "   id  timestamp   accel_x   accel_y  accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  17        0.0  0.147291  9.492709    -2.46 -0.003333 -0.002967 -0.006294   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "34519\n",
            "8630\n",
            "Unique labels: [nan  0.  1.  2.  3.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 7048 occurrences\n",
            "Label 2.0: 667 occurrences\n",
            "Label 1.0: 463 occurrences\n",
            "Label 3.0: 442 occurrences\n",
            "   id  timestamp   accel_x   accel_y  accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  18        0.0 -0.143057  9.490828     2.37 -0.003018  0.002382  0.007302   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "44905\n",
            "11226\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 9273 occurrences\n",
            "Label 3.0: 1017 occurrences\n",
            "Label 2.0: 533 occurrences\n",
            "Label 1.0: 397 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  19        0.0  2.619248  9.219248  2.320752  0.002963 -0.010249 -0.005926   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "45319\n",
            "11330\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 8882 occurrences\n",
            "Label 3.0: 1020 occurrences\n",
            "Label 2.0: 797 occurrences\n",
            "Label 1.0: 621 occurrences\n",
            "   id  timestamp   accel_x  accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  20        0.0 -0.226662     9.07  3.480012  0.002707 -0.008122 -0.005212   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "48125\n",
            "12031\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 9509 occurrences\n",
            "Label 3.0: 1120 occurrences\n",
            "Label 2.0: 826 occurrences\n",
            "Label 1.0: 575 occurrences\n",
            "   id  timestamp   accel_x   accel_y  accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  21        0.0 -0.024839  9.237741  3.14258 -0.000125 -0.003452 -0.000618   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "59562\n",
            "14891\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 12276 occurrences\n",
            "Label 3.0: 1588 occurrences\n",
            "Label 1.0: 544 occurrences\n",
            "Label 2.0: 482 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z   gyro_x    gyro_y    gyro_z  \\\n",
            "0  22        0.0  0.841506  8.734247  4.251506 -0.00111 -0.004234 -0.000206   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "45129\n",
            "11282\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 8494 occurrences\n",
            "Label 3.0: 2042 occurrences\n",
            "Label 2.0: 400 occurrences\n",
            "Label 1.0: 344 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  23        0.0  1.173026  8.929436  3.785846  0.002355 -0.005556 -0.001045   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "51761\n",
            "12940\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 9443 occurrences\n",
            "Label 3.0: 2408 occurrences\n",
            "Label 2.0: 691 occurrences\n",
            "Label 1.0: 398 occurrences\n",
            "   id  timestamp   accel_x   accel_y  accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  24        0.0  0.484567  8.438189     4.87 -0.004444 -0.010754 -0.013333   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "46201\n",
            "11550\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 7916 occurrences\n",
            "Label 3.0: 2712 occurrences\n",
            "Label 2.0: 540 occurrences\n",
            "Label 1.0: 382 occurrences\n",
            "   id  timestamp   accel_x   accel_y  accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  25        0.0  1.713444  9.527311    -1.59 -0.004212 -0.008453 -0.018671   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "46989\n",
            "11747\n",
            "Unique labels: [nan  0.  3.  2.  1.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 8439 occurrences\n",
            "Label 3.0: 2638 occurrences\n",
            "Label 2.0: 542 occurrences\n",
            "Label 1.0: 121 occurrences\n",
            "   id  timestamp   accel_x  accel_y   accel_z    gyro_x   gyro_y    gyro_z  \\\n",
            "0  26        0.0  1.350392  9.28719 -2.773595  0.005012 -0.00056 -0.000552   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "44641\n",
            "11160\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 7178 occurrences\n",
            "Label 3.0: 3204 occurrences\n",
            "Label 2.0: 426 occurrences\n",
            "Label 1.0: 352 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  27        0.0  2.431313  9.494781  0.885219 -0.028974 -0.029575 -0.040856   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "39439\n",
            "9860\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 7562 occurrences\n",
            "Label 3.0: 1634 occurrences\n",
            "Label 2.0: 405 occurrences\n",
            "Label 1.0: 249 occurrences\n",
            "   id  timestamp   accel_x  accel_y   accel_z   gyro_x   gyro_y    gyro_z  \\\n",
            "0  28        0.0  0.221646     8.46  4.836329 -0.00135 -0.01484 -0.014444   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n",
            "49081\n",
            "12270\n",
            "Unique labels: [nan  0.  1.  3.  2.]\n",
            "\n",
            "Label counts:\n",
            "Label 0.0: 6152 occurrences\n",
            "Label 3.0: 5263 occurrences\n",
            "Label 2.0: 447 occurrences\n",
            "Label 1.0: 408 occurrences\n",
            "   id  timestamp   accel_x   accel_y   accel_z    gyro_x    gyro_y    gyro_z  \\\n",
            "0  29        0.0  1.677089  9.653418  0.216836 -0.003305 -0.001139 -0.010541   \n",
            "\n",
            "   label  \n",
            "0    NaN  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "\n",
        "def preprocess_data(x_file_path, y_file_path):\n",
        "    # Load data\n",
        "    x_data = pd.read_csv(x_file_path, header=None , names=['timestamp', 'accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z'])\n",
        "    y_data = pd.read_csv(y_file_path, header=None ,names=['timestamp', 'label'])\n",
        "\n",
        "    print(len(x_data))\n",
        "    print(len(y_data))\n",
        "    # Calculate the number of iterations for merging\n",
        "    num_iterations = len(x_data) // 40\n",
        "\n",
        "    # Initialize list to store merged data\n",
        "    merged_data = []\n",
        "\n",
        "    # Merge data by adding y_train values at specific positions in x_train\n",
        "    for i in range(num_iterations):\n",
        "        # Extract 40 rows from x_data and 10 rows from y_data\n",
        "        x_sample = x_data.iloc[i * 40: (i + 1) * 40]\n",
        "        y_sample = y_data.iloc[i * 10: (i + 1) * 10]\n",
        "\n",
        "        # Merge y_sample into x_sample at positions multiples of 4\n",
        "        for j, y_index in enumerate(range(3, 40, 4)):\n",
        "            x_sample = x_sample.copy()\n",
        "            x_sample.loc[x_sample.index[y_index], 'label'] = y_sample.iloc[j, 1]\n",
        "\n",
        "        # Append the modified x_sample to merged_data\n",
        "        merged_data.append(x_sample)\n",
        "\n",
        "    # Concatenate the list of dataframes into a single dataframe\n",
        "    merged_data = pd.concat(merged_data)\n",
        "\n",
        "    trial_id = int(x_file_path.split('/')[-1].split('_')[0][5:])\n",
        "    merged_data.insert(0, 'id', trial_id)\n",
        "\n",
        "    unique_labels = merged_data['label'].unique()\n",
        "    print(\"Unique labels:\", unique_labels)\n",
        "\n",
        "    label_counts = merged_data['label'].value_counts()\n",
        "    print(\"\\nLabel counts:\")\n",
        "    for label, count in label_counts.items():\n",
        "        print(f\"Label {label}: {count} occurrences\")\n",
        "    print(merged_data.head(1))\n",
        "    return merged_data\n",
        "\n",
        "\n",
        "\n",
        "# List of trial IDs\n",
        "trial_ids = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\",\n",
        "             \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\",\n",
        "             \"21\", \"22\", \"23\", \"24\",\"25\", \"26\", \"27\", \"28\", \"29\"]\n",
        "\n",
        "# trial_ids = [\"01\"]\n",
        "train_df = pd.DataFrame()\n",
        "\n",
        "# Process each trial data\n",
        "for trial_id in trial_ids:\n",
        "    x_file_path = f\"drive/MyDrive/GaitData/data/train/Trial{trial_id}_x.csv\"\n",
        "    y_file_path = f\"drive/MyDrive/GaitData/data/train/Trial{trial_id}_y.csv\"\n",
        "    combined_data = preprocess_data(x_file_path, y_file_path)\n",
        "\n",
        "\n",
        "    # Append preprocessed data to lists\n",
        "    train_df = pd.concat([train_df,combined_data] , ignore_index=True)\n",
        "\n",
        "label_counts = train_df[\"label\"].value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0jUt8OXNhkM",
        "outputId": "1137bc1f-94c6-413a-cff5-beff3b9beae5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1370320\n"
          ]
        }
      ],
      "source": [
        "print(len(train_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG-o44zyH1ut"
      },
      "outputs": [],
      "source": [
        "# Create sequences and labels for each trial ID\n",
        "trial_ids_train = [x for x in range(1, 30) if x not in (2, 11, 25)]\n",
        "\n",
        "num_sensors = 6\n",
        "sequence_length = 40\n",
        "all_sequences_train = []\n",
        "all_labels_train = []\n",
        "all_trial_ids_train = []\n",
        "for trial_id in trial_ids_train:\n",
        "    trial_data = train_df[train_df['id'] == trial_id]\n",
        "    num_sequences = len(trial_data) - sequence_length + 1\n",
        "    for i in range(num_sequences):\n",
        "        start_index = i\n",
        "        end_index = start_index + sequence_length\n",
        "        sequence_data = trial_data.iloc[start_index:end_index].drop(columns=['label', 'id', 'timestamp'])\n",
        "        sequence_data_label = trial_data.iloc[start_index:end_index].drop(columns=['timestamp', 'accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z'])\n",
        "        all_sequences_train.append(sequence_data.values)\n",
        "        sequence_label = sequence_data_label['label'].mode()[0]  # Mode of labels within the sequence\n",
        "        all_labels_train.append(sequence_label)\n",
        "        all_trial_ids_train.append(trial_id)\n",
        "\n",
        "\n",
        "xTrain = np.array(all_sequences_train)\n",
        "yTrain = np.array(all_labels_train)\n",
        "\n",
        "\n",
        "\n",
        "trial_ids_val = [2, 11, 25]\n",
        "num_sensors = 6\n",
        "sequence_length = 40\n",
        "all_sequences_val = []\n",
        "all_labels_val = []\n",
        "all_trial_ids_val = []\n",
        "for trial_id in trial_ids_val:\n",
        "    trial_data = train_df[train_df['id'] == trial_id]\n",
        "    num_sequences = len(trial_data) - sequence_length + 1\n",
        "    for i in range(num_sequences):\n",
        "        start_index = i\n",
        "        end_index = start_index + sequence_length\n",
        "        sequence_data = trial_data.iloc[start_index:end_index].drop(columns=['label', 'id', 'timestamp'])\n",
        "        sequence_data_label = trial_data.iloc[start_index:end_index].drop(columns=['timestamp', 'accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z'])\n",
        "        all_sequences_val.append(sequence_data.values)\n",
        "        sequence_label = sequence_data_label['label'].mode()[0]  # Mode of labels within the sequence\n",
        "        all_labels_val.append(sequence_label)\n",
        "        all_trial_ids_val.append(trial_id)\n",
        "\n",
        "xVal = np.array(all_sequences_val)\n",
        "yVal = np.array(all_labels_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W66c0wfnJRUZ",
        "outputId": "1030ba5e-4a9d-4186-c650-b69fbb9ed0d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1204186, 40, 6) (1204186,)\n",
            "(165003, 40, 6) (165003,)\n",
            "Class distribution after undersampling:\n",
            "Value 0.0: 12409 occurrences\n",
            "Value 1.0: 12409 occurrences\n",
            "Value 2.0: 12409 occurrences\n",
            "Value 3.0: 12409 occurrences\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# xTrain = xTrain.reshape(xTrain.shape[0], xTrain.shape[1], xTrain.shape[2], 1)\n",
        "# xVal = xVal.reshape(xVal.shape[0], xVal.shape[1], xVal.shape[2], 1)\n",
        "input_shape =  (40, 6)\n",
        "\n",
        "\n",
        "print(xTrain.shape, yTrain.shape)\n",
        "print(xVal.shape, yVal.shape)\n",
        "\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Define undersampler targeting the majority class (Value 0)\n",
        "undersampler = RandomUnderSampler(sampling_strategy={0: 12409, 1: 12409, 2: 12409, 3: 12409})\n",
        "\n",
        "# Reshape data for undersampling\n",
        "xTrain_reshaped = xTrain.reshape(xTrain.shape[0], -1)\n",
        "\n",
        "# Perform undersampling\n",
        "xTrain_resampled, yTrain_resampled = undersampler.fit_resample(xTrain_reshaped, yTrain)\n",
        "\n",
        "# Reshape back to original shape\n",
        "xTrain_resampled = xTrain_resampled.reshape(-1, sequence_length, num_sensors)\n",
        "\n",
        "# Check class distribution after undersampling\n",
        "print(\"Class distribution after undersampling:\")\n",
        "unique, counts = np.unique(yTrain_resampled, return_counts=True)\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Value {label}: {count} occurrences\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZy-LVrfum0E"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "\n",
        "# def build_model():\n",
        "#     model = Sequential()\n",
        "#     model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "#     model.add(MaxPooling1D(pool_size=2))\n",
        "#     model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
        "#     model.add(MaxPooling1D(pool_size=2))\n",
        "#     model.add(Flatten())\n",
        "#     model.add(Dense(128, activation='relu'))\n",
        "#     model.add(Dropout(0.5))  # Adding dropout layer\n",
        "#     model.add(Dense(4, activation='softmax'))  # Assuming 4 output classes\n",
        "#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "#     return model\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3), padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=(3, 3), padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        self.fc1 = nn.Linear(128 * 10 * 1, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, n_classes)  # Assuming num_classes is defined elsewhere\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm1d(128)\n",
        "        self.bn5 = nn.BatchNorm1d(64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = x.unsqueeze(1)  # Add channel dimension\n",
        "        x = self.bn1(F.relu(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        # print(x.shape)\n",
        "        x = self.bn2(F.relu(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        # print(x.shape)\n",
        "        x = self.bn3(F.relu(self.conv3(x)))\n",
        "        # print(x.shape)\n",
        "        x = x.view(-1, 128 * 10 * 1)\n",
        "        # print(x.shape)\n",
        "        x = self.bn4(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.bn5(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        # print(x.shape)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3up86pFDqcLg"
      },
      "outputs": [],
      "source": [
        "n_classes = len(np.unique(yTrain))\n",
        "\n",
        "model = CNN()\n",
        "\n",
        "weights = torch.tensor(compute_class_weight(class_weight='balanced',classes=np.unique(yTrain),y=yTrain), dtype=torch.float)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# # Evaluate the model\n",
        "# test_loss, test\\_accuracy = model.evaluate(xVal, yVal)\n",
        "# y_pred = model.predict(xVal)\n",
        "# y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "# cm = confusion_matrix(yVal, y_pred_labels)\n",
        "# print('Confusion Matrix:', cm)\n",
        "# print('Classification Report:', classification_report(yVal, y_pred_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySdrZF9wtJDW"
      },
      "outputs": [],
      "source": [
        "# Define DataLoader for training data\n",
        "x_train_tensor = torch.tensor(xTrain, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(yTrain, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "\n",
        "x_val_tensor = torch.tensor(xVal, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(yVal, dtype=torch.long)\n",
        "\n",
        "# Assuming you have validation data x_val and y_val, convert them to PyTorch tensors as well\n",
        "\n",
        "# Define DataLoader for training data\n",
        "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_gjSWlTriac",
        "outputId": "2916d424-7394-46d9-ce49-6e1c621ec4cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:   0. Loss: 0.1785. Acc.: 90.42% Bal Acc.: 94.02%              Val Loss: 0.3373 Val Acc.: 86.22%   Val Bal Acc.: 92.10%  time: 917.46s   trial: 0\n",
            "Epoch 0 best model saved with accuracy: 92.10%\n",
            "Epoch:   1. Loss: 0.1053. Acc.: 93.79% Bal Acc.: 96.50%              Val Loss: 0.2353 Val Acc.: 91.08%   Val Bal Acc.: 93.83%  time: 907.31s   trial: 0\n",
            "Epoch 1 best model saved with accuracy: 93.83%\n",
            "Epoch:   2. Loss: 0.0835. Acc.: 94.93% Bal Acc.: 97.24%              Val Loss: 0.2496 Val Acc.: 91.44%   Val Bal Acc.: 93.89%  time: 902.74s   trial: 0\n",
            "Epoch 2 best model saved with accuracy: 93.89%\n",
            "Epoch:   3. Loss: 0.0708. Acc.: 95.60% Bal Acc.: 97.67%              Val Loss: 0.2313 Val Acc.: 92.66%   Val Bal Acc.: 94.00%  time: 917.37s   trial: 1\n",
            "Epoch 3 best model saved with accuracy: 94.00%\n",
            "Epoch:   4. Loss: 0.0617. Acc.: 96.11% Bal Acc.: 97.98%              Val Loss: 0.2403 Val Acc.: 92.39%   Val Bal Acc.: 93.80%  time: 896.12s   trial: 0\n",
            "Epoch:   5. Loss: 0.0555. Acc.: 96.50% Bal Acc.: 98.20%              Val Loss: 0.2680 Val Acc.: 91.63%   Val Bal Acc.: 94.09%  time: 891.24s   trial: 1\n",
            "Epoch 5 best model saved with accuracy: 94.09%\n",
            "Epoch:   6. Loss: 0.0515. Acc.: 96.76% Bal Acc.: 98.34%              Val Loss: 0.2368 Val Acc.: 93.04%   Val Bal Acc.: 93.48%  time: 874.81s   trial: 2\n",
            "Epoch:   7. Loss: 0.0484. Acc.: 96.98% Bal Acc.: 98.45%              Val Loss: 0.2395 Val Acc.: 93.22%   Val Bal Acc.: 93.72%  time: 886.30s   trial: 3\n"
          ]
        }
      ],
      "source": [
        "patience, trials = 15, 0\n",
        "best_acc, best_loss = 0, float('inf')\n",
        "# Training loop\n",
        "for epoch in range(8):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_truth, train_pred = [], []\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        train_pred.extend(preds.cpu().numpy())\n",
        "        train_truth.extend(targets.numpy())\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # sched.step()\n",
        "        train_loss += loss.item()\n",
        "    train_acc = accuracy_score(train_truth, train_pred)\n",
        "    train_bal_acc = balanced_accuracy_score(train_truth, train_pred)\n",
        "    # print(outputs)\n",
        "    # print(np.array(train_pred).sum())\n",
        "    # print(np.array(train_truth).sum())\n",
        "    val_truth = []\n",
        "    val_pred = []\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for inputs, targets in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            val_pred.extend(preds.cpu().numpy())\n",
        "            val_truth.extend(targets.numpy())\n",
        "            loss = criterion(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "    # print(np.array(val_pred).sum())\n",
        "    # print(np.array(val_truth).sum())\n",
        "    val_acc = accuracy_score(val_truth, val_pred)\n",
        "    val_bal_acc = balanced_accuracy_score(val_truth, val_pred)\n",
        "    if epoch % 1 == 0:\n",
        "        print(f'Epoch: {epoch:3d}. Loss: {train_loss/len(train_loader):.4f}. Acc.: {train_acc:2.2%} Bal Acc.: {train_bal_acc:2.2%}  \\\n",
        "            Val Loss: {val_loss/len(val_loader):.4f} Val Acc.: {val_acc:2.2%}   Val Bal Acc.: {val_bal_acc:2.2%}  time: {time.time() - start:.2f}s   trial: {trials}')\n",
        "    if val_bal_acc > best_acc:\n",
        "        best_acc = val_bal_acc\n",
        "        torch.save(model.state_dict(), 'best.pth')\n",
        "        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
        "    if val_loss < best_loss:\n",
        "        trials = 0\n",
        "        best_loss = val_loss\n",
        "    else:\n",
        "        trials += 1\n",
        "        if trials >= patience:\n",
        "            print(f'Early stopping on epoch {epoch}')\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD9w2CBsecBq"
      },
      "outputs": [],
      "source": [
        "def extractFeat(xt,xv,winSz,timeStart,timeEnd,timeStep):\n",
        "    tList = []\n",
        "    featList = []\n",
        "\n",
        "    # Specifying the initial window for extracting features\n",
        "    t0 = timeStart\n",
        "    t1 = t0+winSz\n",
        "\n",
        "    while(t1<=timeEnd):\n",
        "        # Using the middle time of the window as a reference time\n",
        "        tList.append((t0+t1)/2)\n",
        "\n",
        "        # Extracting features\n",
        "        xWin = xv[(xt>=t0)*(xt<=t1),:]\n",
        "        # f1 = np.mean(xWin,axis=0)\n",
        "        # f2 = np.std(xWin,axis=0)\n",
        "\n",
        "        # Storing the features\n",
        "        featList.append(xWin)\n",
        "        # featList.append(np.concatenate((f1,f2)))\n",
        "\n",
        "        # Updating the window by shifting it by the step size\n",
        "        t0 = t0+timeStep\n",
        "        t1 = t0+winSz\n",
        "\n",
        "    tList = np.array(tList)\n",
        "    featList = np.array(featList)\n",
        "\n",
        "    return tList, featList\n",
        "\n",
        "def loadTrial(dataFolder,id):\n",
        "    x = np.genfromtxt('{}Trial{:02d}_x.csv'.format(dataFolder,id),delimiter=',')\n",
        "    xt = x[:,0]\n",
        "    xv = x[:,1:]\n",
        "    y = np.genfromtxt('{}Trial{:02d}_y.csv'.format(dataFolder,id),delimiter=',')\n",
        "    yt = y[:,0]\n",
        "    yv = y[:,1].astype(int)\n",
        "\n",
        "    # Returning x measurements and y labels\n",
        "    return xt, xv, yt, yv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZZNldkfSfM-",
        "outputId": "4098d591-fd52-4cea-854e-e64c6d08ad0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-32-d2cbc53f50d6>:37: RuntimeWarning: invalid value encountered in cast\n",
            "  yv = y[:,1].astype(int)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drive/MyDrive/Predictions/Trial01_y.csv\n",
            "drive/MyDrive/Predictions/Trial02_y.csv\n",
            "drive/MyDrive/Predictions/Trial03_y.csv\n",
            "drive/MyDrive/Predictions/Trial04_y.csv\n"
          ]
        }
      ],
      "source": [
        "pred_path = Path('drive/MyDrive/Predictions')\n",
        "pred_path.mkdir(exist_ok=True)\n",
        "timeStep = 0.1\n",
        "winSz = 1\n",
        "test_path = 'drive/MyDrive/GaitData/data/test/'\n",
        "testIDs = [1,2,3,4]\n",
        "\n",
        "\n",
        "for k,id in enumerate(testIDs):\n",
        "        # Loading the raw data\n",
        "        xt, xv, yt, yv = loadTrial(test_path,id=id)\n",
        "        pred_trial_path = pred_path/f'Trial{id:02d}_y.csv'\n",
        "\n",
        "        # Extracting the time window for which we have values for the measurements and the response\n",
        "        timeStart = np.max((np.min(xt),np.min(yt)))\n",
        "        timeEnd = np.min((np.max(xt),np.max(yt)))\n",
        "\n",
        "        # Extracting the features\n",
        "        _, feat = extractFeat(xt,xv,winSz,timeStart,timeEnd,timeStep)\n",
        "        x_test_tensor = torch.tensor(np.array(feat), dtype=torch.float32)\n",
        "        # Assuming you have validation data x_val and y_val, convert them to PyTorch tensors as well\n",
        "\n",
        "        # Define DataLoader for training data\n",
        "        test_dataset = TensorDataset(x_test_tensor)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            preds = []\n",
        "            for [inputs] in test_loader:\n",
        "                outputs = model(inputs)\n",
        "                preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
        "        # preds = network.predict(np.array(feat)).tolist()\n",
        "        if len(preds) < len(yt):\n",
        "            preds.extend([preds[-1]] * (len(yt) - len(preds)))\n",
        "        shutil.copy('{}Trial{:02d}_x.csv'.format(test_path,id), pred_path)\n",
        "        yt = np.array(yt)[:, np.newaxis]\n",
        "        preds = np.array(preds)[:, np.newaxis]\n",
        "        out = np.hstack((yt, preds))\n",
        "        np.savetxt(pred_trial_path, out, delimiter=',')\n",
        "        print(pred_trial_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}